{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_cheatsheet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6NGhnZu-vjAE",
        "s_-JgCWwvxx4",
        "7bkCDlyCwNlF",
        "tixZYo20yitP",
        "jTY4FUhByxx4",
        "430X8Oxwy7ot",
        "AnP3c7ztzMIn",
        "_Lk_fR_szUhm",
        "-2YbJq5KzmB1"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNKRHd2NXm1gtxnV/Rqby6H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ascherf-ml/ML-cheat-sheet/blob/master/ML_cheatsheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NGhnZu-vjAE",
        "colab_type": "text"
      },
      "source": [
        "# Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_b4E0QtsgIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Jan 2020\n",
        "\n",
        "\"\"\"\n",
        "# =============================================================================\n",
        "# 1. Import modules\n",
        "# =============================================================================\n",
        "# 1.1 Handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns',100) #reduce visible columns\n",
        "\n",
        "# 1.2 Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rc(\"font\", size=14)\n",
        "plt.close('all')\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\")\n",
        "sns.set(style=\"whitegrid\", color_codes=True)\n",
        "sns.set(font_scale=1.5)\n",
        "\n",
        "# 1.3 ML Base\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 1.4 ML Analysis\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import ElasticNetCV\n",
        "from sklearn.linear_model import TheilSenRegressor\n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import log_loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_-JgCWwvxx4",
        "colab_type": "text"
      },
      "source": [
        "# Import Databases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX8kNCcWvsDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 2. Data Ingestion\n",
        "# =============================================================================\n",
        "'''\n",
        "Identify and gather the data you want to work with.\n",
        "'''\n",
        "data = pd.read_csv('C:\\\\Users\\\\nucular\\\\Desktop\\\\ML\\\\cheatsheet\\\\data.csv',sep=';')\n",
        "#data=pd.read_excel('data.xlsx', index_col=0)\n",
        "#data=pd.read_hdf('data.h5', 'data')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bkCDlyCwNlF",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation and exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsgiN3rGwBec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 3. Data Preparation\n",
        "# =============================================================================\n",
        "'''\n",
        "Since the data is raw and unstructured, it is rarely in the correct form to be processed. \n",
        "It usually involves filling missing values or removing duplicate records or \n",
        "normalising and correcting other flaws in data, like different representations \n",
        "of the same values in a column for instance. \n",
        "This is where the feature extraction, construction and selection takes place too.\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgxR_vwcwIU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 3.1 Data exploration\n",
        "# =============================================================================\n",
        "\n",
        "# 3.1.1 What is N, how many Variables\n",
        "print (data.shape) \n",
        "\n",
        "# 3.1.2 Show Dataset\n",
        "# What does the data look like, varnames and first 3 entries\n",
        "print (data.head(3)) \n",
        "\n",
        "# 3.1.3 Show every variable with every unique property\n",
        "cat_list=list(data.columns)\n",
        "print (cat_list)\n",
        "\n",
        "for i in cat_list:\n",
        "    print (i)\n",
        "    print (data[i].unique())\n",
        "\n",
        "# 3.1.4 Show missings\n",
        "print (data.isnull().sum())\n",
        "\n",
        "\n",
        "# 3.1.5 Count different variable outcomes\n",
        "count_var = len(data[data['y']=='yes']) \n",
        "print (count_var)\n",
        "\n",
        "# 3.1.6 View different outcomes grouped by variable\n",
        "print (data.groupby('y').mean()) \n",
        "\n",
        "# 3.1.7 View distribution of categorial variable\n",
        "imp = data.poutcome.value_counts(normalize=True)\n",
        "print (imp)\n",
        "\n",
        "# 3.1.8 View plots with different variable configurations\n",
        "\n",
        "def scatter_plot(feature, target):\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.scatter(\n",
        "        data[feature],\n",
        "        data[target],\n",
        "        c='black'\n",
        "    )\n",
        "    plt.xlabel(\"X Label\".format(feature))\n",
        "    plt.ylabel(\"Y Label\")\n",
        "    plt.show()\n",
        "\n",
        "scatter_plot('age', 'balance')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tixZYo20yitP",
        "colab_type": "text"
      },
      "source": [
        "# Data/Missings handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP2IkixGwYVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# =============================================================================\n",
        "# 3.2 Missings handling\n",
        "# =============================================================================\n",
        "\n",
        "# 3.2.1 Delete rows with NaN missings; (axis=1) deletes columns \n",
        "data.dropna(axis=0)\n",
        "\n",
        "\n",
        "# 3.2.2 Imputation with mean for specific variables\n",
        "data['balance'] = data['balance'].fillna((data['balance'].mean()))\n",
        "\n",
        "# 3.2.3 Imputation with mean for all variables\n",
        "data.fillna(data.mean())\n",
        "\n",
        "\n",
        "# 3.2.4 Imputation of categorial variables based on distribution\n",
        "imp = data.poutcome.value_counts(normalize=True) # show distribution\n",
        "print (imp)\n",
        "\n",
        "data.replace('unknown', np.nan, inplace=True) # replace values with NaN\n",
        "missing = data['poutcome'].isnull()  # define missings\n",
        "\n",
        "imp = data.poutcome.value_counts(normalize=True) # redefine distribution\n",
        "\n",
        "data.loc[missing,'poutcome'] = np.random.choice(imp.index, size=len(data[missing]),p=imp.values) # replace missings with distribution\n",
        "print(data['poutcome'].unique())\n",
        "\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 3.3 Data handling\n",
        "# =============================================================================\n",
        "\n",
        "# 3.3.1 Binarization of Variables; 0/1 dummy output\n",
        "data['y'] = (data['y']=='yes').astype(int)\n",
        "print (data['y'].value_counts())\n",
        "\n",
        "\n",
        "data['default'] = (data['default']=='yes').astype(int)\n",
        "data['housing'] = (data['housing']=='yes').astype(int)\n",
        "data['loan'] = (data['loan']=='yes').astype(int)\n",
        "\n",
        "\n",
        "# 3.3.2 Dichotomization of categorial variabes; creates k 0/1dummies\n",
        "cat_list = ['job','marital','education','contact','month','poutcome'] #create list of all categorial variables\n",
        "\n",
        "for i in cat_list:\n",
        " add = pd.get_dummies(data[i], prefix=i)\n",
        " data1 = data.join(add)# join columns with old dataframe\n",
        " data = data1\n",
        "print (data.head(3))\n",
        "print (data.info())\n",
        "\n",
        "\n",
        "# 3.3.3 Standardize features\n",
        "'''\n",
        "Many elements used in the objective function of a learning algorithm \n",
        "(such as the RBF kernel of Support Vector Machines or the L1 and L2 regularizers of linear models) \n",
        "assume that all features are centered around 0 and have variance in the same order. \n",
        "If a feature has a variance that is orders of magnitude larger that others, \n",
        "it might dominate the objective function and make the estimator \n",
        "unable to learn from other features correctly as expected.\n",
        "'''\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "print(scaler.mean_)\n",
        "scaler.transform(X_train)\n",
        "data_scal = scaler.fit_transform(data_fin)\n",
        "\n",
        "data_scal = pd.DataFrame(data=data_scal, index=data_fin.index, columns=data_fin.columns)\n",
        "\n",
        "\n",
        "# 3.3.4 Cleaning the database\n",
        "new_vars = data.columns.values.tolist() #column headers are converted into a list\n",
        "to_keep = [i for i in new_vars if i not in cat_list] #create a new list by comparing with the list of categorical variables - 'cat_list'\n",
        "print (to_keep) #check the list of headers \n",
        "\n",
        "data_fin = data[to_keep]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTY4FUhByxx4",
        "colab_type": "text"
      },
      "source": [
        "# Dimensionality reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J9xkEJeyrGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 3.4 Dimensionality reduction\n",
        "# =============================================================================\n",
        "\n",
        "# 3.4.1 Recursive Feature Elimination (RFE)\n",
        "'''\n",
        "If there are to many IV. Only keeps the most important ones. \n",
        "Logistic Regression is the base. Only for binary dependent variables.\n",
        "'''\n",
        "data_final_vars=data_fin.columns.values.tolist()# converting the headers into a list\n",
        "Y = ['y']\n",
        "X = [i for i in data_final_vars if i not in Y]\n",
        "\n",
        "\n",
        "\n",
        "model = LogisticRegression()\n",
        "rfe = RFE(model, 15) #selected k=15 features\n",
        "rfe = rfe.fit(data_fin[X], data_fin[Y])\n",
        "\n",
        "rfe_rankinglist = rfe.ranking_.tolist()\n",
        "selected_columns = []\n",
        "for i in range(len(X)):\n",
        " if rfe_rankinglist[i]==1:\n",
        "  selected_columns.append(X[i]) \n",
        "print (selected_columns) #show all selected features\n",
        "print (rfe.ranking_) #show all selected features by ranking up to k-features\n",
        "X_new = data_fin[selected_columns]\n",
        "\n",
        "\n",
        "\n",
        "# 3.4.2 Correlation matrix\n",
        "'''\n",
        "If there are to many feature variables. Only keeps the one with high correlation factor. \n",
        "Only for metric dependent variables.\n",
        "'''\n",
        "correlation = data.corr(method='pearson')\n",
        "columns = correlation.nlargest(15, 'balance').index\n",
        "\n",
        "correlation_map = np.corrcoef(data[columns].values.T)\n",
        "sns.set(font_scale=1.0)\n",
        "heatmap = sns.heatmap(correlation_map, cbar=True, annot=True, square=True, fmt='.2f', yticklabels=columns.values, xticklabels=columns.values)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "430X8Oxwy7ot",
        "colab_type": "text"
      },
      "source": [
        "# Data Segregation\n",
        "In train and test samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GWZzTR8y2mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# =============================================================================\n",
        "# 4. Data Segregation\n",
        "# =============================================================================\n",
        "'''\n",
        "Split subsets of data to train the model, test it and further validate how it performs against new data.\n",
        "'''\n",
        "# 4.1 Separate feature variables and labels\n",
        "data_final_vars=data_fin.columns.values.tolist()# converting the headers into a list\n",
        "Y = data_fin['y']\n",
        "\n",
        "cat_list=list(data_fin.columns)\n",
        "X = data_fin[cat_list]\n",
        "X=X.drop(columns='y')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.30, random_state = 10) #keep 30% of data as test dataset\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnP3c7ztzMIn",
        "colab_type": "text"
      },
      "source": [
        "# Regression models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M7qBQFOzFqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "f8d36b09-53b2-422a-e9b9-7ce20756170a"
      },
      "source": [
        "# =============================================================================\n",
        "# 5. Model Training\n",
        "# =============================================================================\n",
        "'''\n",
        "Use the training subset of data to let the ML algorithm recognise the patterns in it.\n",
        "'''\n",
        "# 5.1 Linear Models\n",
        "# 5.1.1 Linear Regression\n",
        "lin = LinearRegression()\n",
        "pred_lin = lin.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "y_predlin=lin.predict(X_test)\n",
        "print ('Betas: ', list(zip(lin.coef_, X)))\n",
        "print ('Beta0: %.2f' % lin.intercept_) #Beta0\n",
        "print ('R²: %.2f' % lin.score(X,Y)) #R²\n",
        "print ('MSE: %.2f' % mean_squared_error(y_test, y_predlin)) # MSE\n",
        "print ('Variance score: %.2f' % r2_score(y_test, y_predlin)) \n",
        "\n",
        "cv_results = cross_val_score(lin, X_train, y_train, scoring='neg_mean_squared_error')\n",
        "msg = \"%s: %f (%f)\" % (lin, cv_results.mean(), cv_results.std())\n",
        "print(msg)\n",
        "\n",
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_predlin})\n",
        "print (df)\n",
        "\n",
        "\n",
        "\n",
        "# 5.1.2.1 Ridge Regression\n",
        "'''\n",
        "Imposing a penalty on the size of the coefficients (the more the higher the penalty)\n",
        "Used when the data suffers from multicollinearity, because of penalization\n",
        "By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors.\n",
        "Normality is not to be assumed.\n",
        "'''\n",
        "ridge = Ridge(alpha=.5)\n",
        "pred_ridge = ridge.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "y_ridge=ridge.predict(X_test)\n",
        "print(list(zip(ridge.coef_, X)))\n",
        "print(ridge.intercept_) #Beta0\n",
        "print (ridge.score(X,Y)) #R²\n",
        "print (mean_squared_error(y_test, y_ridge)) # MSE\n",
        "\n",
        "\n",
        "\n",
        "# 5.1.2.2 Ridge Regression with crossvalidation to calculate optimal alpha\n",
        "''' \n",
        "Cross-Validation (CV):\n",
        "Divide the training data into 10 different parts and compute average the prediction error between every part. \n",
        "'''\n",
        "\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]}\n",
        "\n",
        "ridge_alpha = GridSearchCV(ridge, parameters,scoring='neg_mean_squared_error', cv=5)\n",
        "ridge_alpha.fit(X, Y)\n",
        "\n",
        "\n",
        "print (\"Optimal alpha score: \", ridge_alpha.best_params_)\n",
        "print (\"Highest possible Negative-MSE: \", ridge_alpha.best_score_) \n",
        "\n",
        "\n",
        "\n",
        "# 5.1.3.1 Lasso (Least Absolute Shrinkage and Selection Operator) Regression\n",
        "'''\n",
        "Penalizes the absolute size of the regression coefficients. \n",
        "In addition, it is capable of reducing the variability and improving the \n",
        "accuracy of linear regression models. \n",
        "Normality is not to be assumed.\n",
        "It shrinks coefficients to zero, which helps in feature selection.\n",
        "If group of predictors are highly correlated, lasso picks only one of them and shrinks the others to zero\n",
        "'''\n",
        "\n",
        "lasso = Lasso(alpha=.5)\n",
        "pred_lasso = lasso.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "y_lasso=lasso.predict(X_test)\n",
        "print(list(zip(lasso.coef_, X)))\n",
        "print(lasso.intercept_) #Beta0\n",
        "print (lasso.score(X,Y)) #R²\n",
        "print (mean_squared_error(y_test, y_lasso)) # MSE\n",
        "\n",
        "\n",
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_lasso})\n",
        "print (df)\n",
        "\n",
        "\n",
        "\n",
        "# 5.1.3.2 Lasso Regression with crossvalidation to calculate optimal alpha\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]}\n",
        "\n",
        "lasso_alpha = GridSearchCV(lasso, parameters,scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_alpha.fit(X, Y)\n",
        "\n",
        "\n",
        "print (\"Optimal alpha score: \", lasso_alpha.best_params_)\n",
        "print (\"Highest possible Negative-MSE: \", lasso_alpha.best_score_) \n",
        "\n",
        "\n",
        "\n",
        "# 5.1.4.1 Elastic Net Regression\n",
        "elast = ElasticNet(random_state=42)\n",
        "pred_elast = elast.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "y_predelast=elast.predict(X_test)\n",
        "print ('Betas: ', list(zip(elast.coef_, X)))\n",
        "print ('Beta0: %.2f' % elast.intercept_) #Beta0\n",
        "print ('R²: %.2f' % elast.score(X,Y)) #R²\n",
        "print ('MSE: %.2f' % mean_squared_error(y_test, y_predelast))\n",
        "\n",
        "\n",
        "# 5.1.4.1 Elastic Net Regression with crossvalidation to calculate optimal alpha\n",
        "\n",
        "elastcv = ElasticNetCV(cv=5, random_state=42)\n",
        "pred_elastcv = elastcv.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "y_predelastcv = elastcv.predict(X_test)\n",
        "print('Optimal Aplha Value: ', elastcv.alpha_)\n",
        "print ('Betas: ', list(zip(elastcv.coef_, X)))\n",
        "print ('Beta0: %.2f' % elastcv.intercept_) #Beta0\n",
        "print ('R²: %.2f' % elastcv.score(X,Y)) #R²\n",
        "print ('MSE: %.2f' % mean_squared_error(y_test, y_predelastcv))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 5.1.5 Robust regression \n",
        "'''Robust regression aims to fit a regression model in the presence \n",
        "of corrupt data: either outliers, or error in the model\n",
        "\n",
        "\n",
        "HuberRegressor should be faster than RANSAC and Theil Sen unless the number of \n",
        "samples are very large, i.e n_samples >> n_features. This is because RANSAC and \n",
        "Theil Sen fit on smaller subsets of the data. However, both Theil Sen and RANSAC \n",
        "are unlikely to be as robust as HuberRegressor for the default parameters.\n",
        "\n",
        "RANSAC is faster than Theil Sen and scales much better with the number of samples.\n",
        "\n",
        "RANSAC will deal better with large outliers in the y direction (most common situation).\n",
        "\n",
        "Theil Sen will cope better with medium-size outliers in the X direction, \n",
        "but this property will disappear in high-dimensional settings.\n",
        "\n",
        "When in doubt, use RANSAC.\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# 5.1.5.1 RANSAC regression \n",
        "ransac = RANSACRegressor()\n",
        "pred_ransac = ransac.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "y_predransac=ransac.predict(X_test)\n",
        "print ('Betas: ', list(zip(ransac.coef_, X)))\n",
        "print ('Beta0: %.2f' % ransac.intercept_) #Beta0\n",
        "print ('R²: %.2f' % ransac.score(X,Y)) #R²\n",
        "print ('MSE: %.2f' % mean_squared_error(y_test, y_predransac))\n",
        "\n",
        "\n",
        "# 5.1.5.2 Theil-Sen regression \n",
        "ts = TheilSenRegressor()\n",
        "pred_ts = ts.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "y_predts=ts.predict(X_test)\n",
        "print ('Betas: ', list(zip(ts.coef_, X)))\n",
        "print ('Beta0: %.2f' % ts.intercept_) #Beta0\n",
        "print ('R²: %.2f' % ts.score(X,Y)) #R²\n",
        "print ('MSE: %.2f' % mean_squared_error(y_test, y_predts))\n",
        "\n",
        "\n",
        "# 5.1.5.3 Huber regression \n",
        "huber = HuberRegressor(alpha=0.0)\n",
        "pred_huber = huber.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "y_predhuber=huber.predict(X_test)\n",
        "print ('Betas: ', list(zip(huber.coef_, X)))\n",
        "print ('Beta0: %.2f' % huber.intercept_) #Beta0\n",
        "print ('R²: %.2f' % huber.score(X,Y)) #R²\n",
        "print ('MSE: %.2f' % mean_squared_error(y_test, y_predhuber))\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-629ecb92106d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 5.1.1 Linear Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpred_lin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#train the algorithm on training data and predict using the testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_predlin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Betas: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lk_fR_szUhm",
        "colab_type": "text"
      },
      "source": [
        "# Classification models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQLC9cbyzRQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# 5.2 Classification\n",
        "# 5.2.1 Logistic Regression\n",
        "log = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
        "pred_log = log.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "y_pred_log=log.predict(X_test)\n",
        "print(log.predict(X_test)) #predcit results based on the trained model\n",
        "print(\"Logistic Regression accuracy : \",accuracy_score(y_test, pred_log, normalize = True)) #accuracy score of the model\n",
        "print (log.coef_)\n",
        "print(X.columns)\n",
        "\n",
        "df_log = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_log})\n",
        "print (df_log)\n",
        "\n",
        "\n",
        "\n",
        "# 5.2.2 Gaussian Naive Bias (for 0/1)\n",
        "'''\n",
        "Naive-Bayes algorithm calculates the probability of the connection of X with y \n",
        "and then it selects the feature with the highest probability.\n",
        "\n",
        "GaussianNaiveBayes tends to push probabilities to 0 or 1. \n",
        "Caution with datasets containing redundant features.\n",
        "'''\n",
        "gnb = GaussianNB() #create an object of the type GaussianNB\n",
        "pred_gnb = gnb.fit(X_train, y_train).predict(X_test) #train the algorithm on training data and predict using the testing data\n",
        "print(gnb.predict(X_test)) #predcit results based on the trained model\n",
        "print(\"Naive-Bayes accuracy : \",accuracy_score(y_test, pred_gnb, normalize = True)) #accuracy score of the model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 5.2.3 Naive Bayes classifier for multinomial models\n",
        "#mnb = MultinomialNB()\n",
        "\n",
        "\n",
        "# 5.2.4 Linear Support Vector Classification (SVC)\n",
        "'''\n",
        "LinearSVC tries to divide the data into different \n",
        "planes so that it can find a best possible grouping of different classes.\n",
        "'''\n",
        "svc = LinearSVC(random_state=0)\n",
        "pred_svc = svc.fit(X_train, y_train).predict(X_test)\n",
        "print(svc.predict(X_test)) \n",
        "print(\"LinearSVC accuracy : \",accuracy_score(y_test, pred_svc, normalize = True))\n",
        "\n",
        "\n",
        "\n",
        "# 5.2.5 K-Neighbors Classifier\n",
        "kneigh = KNeighborsClassifier(n_neighbors=3)\n",
        "kneigh.fit(X_train, y_train)\n",
        "pred_kneigh = kneigh.predict(X_test)\n",
        "print(kneigh.predict(X_test)) \n",
        "print (\"KNeighbors accuracy : \",accuracy_score(y_test, pred_kneigh))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2YbJq5KzmB1",
        "colab_type": "text"
      },
      "source": [
        "# Classification model selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMyw_qzxziE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# =============================================================================\n",
        "# 6. Candidate Model Evaluation\n",
        "# =============================================================================\n",
        "'''\n",
        "Assess the performance of the model using test and validation subsets of data \n",
        "to understand how accurate the prediction is. This is an iterative process and \n",
        "various algorithms might be tested until you have a Model that sufficiently \n",
        "answers your question.\n",
        "'''\n",
        "# 6.1 Accuracy Score\n",
        "''' \n",
        "number of correct predictions divided by the total number of predictions, multiplied by 100\n",
        "'''\n",
        "print(\"Logistic Regression accuracy :\\n \",accuracy_score(y_test, pred_log, normalize = True))\n",
        "print(\"Naive-Bayes accuracy :\\n \",accuracy_score(y_test, pred_gnb, normalize = True))\n",
        "print(\"LinearSVC accuracy :\\n \",accuracy_score(y_test, pred_svc, normalize = True))\n",
        "print (\"KNeighbors accuracy :\\n \",accuracy_score(y_test, pred_kneigh))\n",
        "\n",
        "# 6.2 Confusion Matrix\n",
        "'''\n",
        "Diagonal elements of this matrix denote the correct prediction for different classes, \n",
        "while the off-diagonal elements denote the samples which are mis-classified.\n",
        "'''\n",
        "print(\"Logistic Regression confusion matrix :\\n \", confusion_matrix(y_test, pred_log))\n",
        "print(\"Naive-Bayes confusion matrix :\\n \", confusion_matrix(y_test, pred_gnb))\n",
        "print(\"LinearSVC confusion matrix :\\n \", confusion_matrix(y_test, pred_svc))\n",
        "print(\"KNeighbors confusion matrix :\\n \", confusion_matrix(y_test, pred_kneigh))\n",
        "\n",
        "\n",
        "# 6.3 Precision Score\n",
        "'''\n",
        "Precision= True_Positive/ (True_Positive+ False_Positive)\n",
        "'''\n",
        "print (\"Logistic Regression precision :\\n \", precision_score(y_test, pred_log, average='binary'))\n",
        "print (\"Naive-Bayes precision :\\n \",precision_score(y_test, pred_gnb, average='binary'))\n",
        "print (\"LinearSVC precision :\\n \",precision_score(y_test, pred_svc, average='binary'))\n",
        "print (\"KNeighbors precision :\\n \",precision_score(y_test, pred_kneigh, average='binary'))\n",
        "\n",
        "\n",
        "# 6.4 F1-Score\n",
        "'''\n",
        "Weighted average of the precision and recall, where an F1 score reaches its best \n",
        "value at 1 and worst score at 0.\n",
        "If you care for a class which is smaller in number independent of the fact whether it is positive or negative, go for ROC-AUC score.\n",
        "When will you prefer F1 over ROC-AUC?\n",
        "When you have a small positive class, then F1 score makes more sense (than ROC-AUC). \n",
        "This is the common problem in fraud detection where positive labels are few. \n",
        "'''\n",
        "print (\"Logistic Regression F1-Score :\\n \", f1_score(y_test, pred_log, average='binary'))\n",
        "print (\"Naive-Bayes F1-Score :\\n \", f1_score(y_test, pred_gnb, average='binary'))\n",
        "print (\"LinearSVC F1-Score :\\n \", f1_score(y_test, pred_svc, average='binary'))\n",
        "print (\"KNeighbors F1-Score :\\n \", f1_score(y_test, pred_kneigh, average='binary'))\n",
        "\n",
        "\n",
        "# 6.5 Classification Report\n",
        "\n",
        "print (\"Logistic Regression Report :\\n \", classification_report(y_test, pred_log))\n",
        "print (\"Naive-Bayes Report :\\n \", classification_report(y_test, pred_gnb))\n",
        "print (\"LinearSVC Report :\\n \", classification_report(y_test, pred_svc))\n",
        "print (\"KNeighbors Report :\\n \", classification_report(y_test, pred_kneigh))\n",
        "\n",
        "\n",
        "\n",
        "# 6.6 Log-Loss (logistic loss or cross-entropy loss)\n",
        "'''\n",
        "It is commonly used in (multinomial) logistic regression and neural networks, it \n",
        "can be used to evaluate the probability outputs (predict_proba) of a \n",
        "classifier instead of its discrete predictions.\n",
        "'''\n",
        "print (\"Logistic Regression log-loss :\\n \", log_loss(y_test, pred_log))\n",
        "print (\"Naive-Bayes log-loss :\\n \", log_loss(y_test, pred_gnb))\n",
        "print (\"LinearSVC log-loss :\\n \", log_loss(y_test, pred_svc))\n",
        "print (\"KNeighbors log-loss :\\n \", log_loss(y_test, pred_kneigh))\n",
        "\n",
        "\n",
        "\n",
        "# 6.7 ROC-Score and AUC-Score\n",
        "'''\n",
        "The receiver operating characteristic curve is plot which shows the performance \n",
        "of a binary classifier as function of its cut-off threshold. \n",
        "It essentially shows the true positive rate (TPR) against the false \n",
        "positive rate (FPR) for various threshold values.\n",
        "\n",
        "The area under the curve (AUC), is an aggregated measure of performance of a \n",
        "binary classifier on all possible threshold values \n",
        "(and therefore it is threshold invariant).\n",
        "AUC calculates the area under the ROC curve, and therefore it is between 0 and 1. \n",
        "One way of interpreting AUC is as the probability that the model ranks a \n",
        "random positive example more highly than a random negative example.\n",
        "'''\n",
        "fpr_log, tpr_log, thresholds = roc_curve(y_test, pred_log)\n",
        "fpr_gnb, tpr_gnb, thresholds = roc_curve(y_test, pred_gnb)\n",
        "fpr_svc, tpr_svc, thresholds = roc_curve(y_test, pred_svc)\n",
        "fpr_kneigh, tpr_kneigh, thresholds = roc_curve(y_test, pred_kneigh)\n",
        "\n",
        "\n",
        "print('Logistic Regression AUC: ', roc_auc_score(y_test, pred_log))\n",
        "print('Naive-Bayes AUC: ', roc_auc_score(y_test, pred_gnb))\n",
        "print('LinearSVC AUC: ', roc_auc_score(y_test, pred_svc))\n",
        "print('KNeighbors AUC: ', roc_auc_score(y_test, pred_kneigh))\n",
        "\n",
        "\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(fpr_log, tpr_log, marker='.', label='Logistic Regression')\n",
        "pyplot.plot(fpr_gnb, tpr_gnb, marker='.', label='Naive-Bayes')\n",
        "pyplot.plot(fpr_svc, tpr_svc, marker='.', label='LinearSVC')\n",
        "pyplot.plot(fpr_kneigh, tpr_kneigh, marker='.', label='KNeighbors')\n",
        "# axis labels\n",
        "pyplot.xlabel('False Positive Rate')\n",
        "pyplot.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "pyplot.legend()\n",
        "# show the plot\n",
        "pyplot.show()\n",
        "\n",
        "\n",
        "\n",
        "# 6.8 Calibration plots\n",
        "plt.figure(figsize=(10, 10))\n",
        "ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
        "ax2 = plt.subplot2grid((3, 1), (2, 0))\n",
        "\n",
        "ax1.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
        "for clf, name in [(log, 'Logistic'),(gnb, 'Naive Bayes'),(svc, 'Support Vector Classification'),(kneigh, 'K-Neighborrs')]:\n",
        "    clf.fit(X_train, y_train)\n",
        "    if hasattr(clf, \"predict_proba\"):\n",
        "        prob_pos = clf.predict_proba(X_test)[:, 1]\n",
        "    else:  # use decision function\n",
        "        prob_pos = clf.decision_function(X_test)\n",
        "        prob_pos = \\\n",
        "            (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
        "    fraction_of_positives, mean_predicted_value = \\\n",
        "        calibration_curve(y_test, prob_pos, n_bins=10)\n",
        "\n",
        "    ax1.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
        "             label=\"%s\" % (name, ))\n",
        "\n",
        "    ax2.hist(prob_pos, range=(0, 1), bins=10, label=name,\n",
        "             histtype=\"step\", lw=2)\n",
        "\n",
        "ax1.set_ylabel(\"Fraction of positives\")\n",
        "ax1.set_ylim([-0.05, 1.05])\n",
        "ax1.legend(loc=\"lower right\")\n",
        "ax1.set_title('Calibration plots  (reliability curve)')\n",
        "\n",
        "ax2.set_xlabel(\"Mean predicted value\")\n",
        "ax2.set_ylabel(\"Count\")\n",
        "ax2.legend(loc=\"upper center\", ncol=2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}